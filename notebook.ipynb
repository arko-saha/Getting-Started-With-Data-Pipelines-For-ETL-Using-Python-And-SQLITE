{"cells":[{"cell_type":"markdown","id":"630ea179-5373-460f-9f23-73fd2c343067","metadata":{},"source":["# Getting Started with Data Pipelines for ETL\n","\n","Data pipelines are everywhere! More than ever, data practitioners find themselves needing to extract, transform, and load data to power the work they do. During this code-along, I'll walk through the basics of building a data pipeline using Python, `pandas`, and `sqlite`. \n","\n","Throughout the tutorial, I'll be using the \"Google Play Store Apps\" dataset, available in DataCamp Workspaces. The two datasets we'll be using is made available as `.csv` files, and will be transformed throughout the code-along before being loaded into a `sqlite` database."]},{"cell_type":"markdown","id":"1808602e-87a7-4405-8298-8c2a25b47930","metadata":{},"source":["# Extracting Data\n","\n","Extracting data is almost always the first step when building a data pipelines. There are tons of shapes and sizes that data can be extracted from. Here are just a few:\n","- API's\n","- SFTP sites\n","- Relational databases\n","- NoSQL databases (columnar, document, key-value)\n","- Flat-files\n","\n","In this code-along, we'll focus on extracting data from flat-files. A flat file might be something like a `.csv` or a `.json` file. The two files that we'll be extracting data from are the `apps_data.csv` and the `review_data.csv` file. To do this, we'll used `pandas`. Let's take a closer look!\n","\n","1. After importing `pandas`, read the `apps_data.csv` DataFrame into memory. Print the head of the DataFrame.\n","2. Similar to before, read in the DataFrame stored in the `review_data.csv` file. Take a look at the first few rows of this DataFrame.\n","3. Print the column names, shape, and data types of the `apps` DataFrame."]},{"cell_type":"code","execution_count":2,"id":"ff5bc9b6-e3ac-4bd1-aeb4-8b106963a16a","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":116,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1707238826195,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import pandas\nimport pandas as pd\n\n# Read the dataset into memory, and take a look at the first few rows (store as apps)\napps = pd.read_csv(\"apps_data.csv\")\nreviews = pd.read_csv(\"review_data.csv\")\n\n# Print out the head of the DataFrame\n#reviews\napps.head(5)\nreviews.head(5)\n\n# Perform some basic checks (column names, number of records, types, etc)\nprint(apps.columns)\nprint(apps.shape)\nprint(apps.dtypes)\n","outputsMetadata":{"0":{"height":397,"type":"stream"},"1":{"height":332,"type":"dataFrame"}}},"outputs":[],"source":["# Import pandas\n","import pandas as pd\n","\n","# Read the dataset into memory, and take a look at the first few rows (store as apps)\n","apps = pd.read_csv(\"apps_data.csv\")\n","reviews = pd.read_csv(\"review_data.csv\")\n"]},{"cell_type":"code","execution_count":5,"id":"6f5c7f5a","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>App</th>\n","      <th>Translated_Review</th>\n","      <th>Sentiment</th>\n","      <th>Sentiment_Polarity</th>\n","      <th>Sentiment_Subjectivity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10 Best Foods for You</td>\n","      <td>I like eat delicious food. That's I'm cooking ...</td>\n","      <td>Positive</td>\n","      <td>1.00</td>\n","      <td>0.533333</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10 Best Foods for You</td>\n","      <td>This help eating healthy exercise regular basis</td>\n","      <td>Positive</td>\n","      <td>0.25</td>\n","      <td>0.288462</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10 Best Foods for You</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10 Best Foods for You</td>\n","      <td>Works great especially going grocery store</td>\n","      <td>Positive</td>\n","      <td>0.40</td>\n","      <td>0.875000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10 Best Foods for You</td>\n","      <td>Best idea us</td>\n","      <td>Positive</td>\n","      <td>1.00</td>\n","      <td>0.300000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     App                                  Translated_Review  \\\n","0  10 Best Foods for You  I like eat delicious food. That's I'm cooking ...   \n","1  10 Best Foods for You    This help eating healthy exercise regular basis   \n","2  10 Best Foods for You                                                NaN   \n","3  10 Best Foods for You         Works great especially going grocery store   \n","4  10 Best Foods for You                                       Best idea us   \n","\n","  Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \n","0  Positive                1.00                0.533333  \n","1  Positive                0.25                0.288462  \n","2       NaN                 NaN                     NaN  \n","3  Positive                0.40                0.875000  \n","4  Positive                1.00                0.300000  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Print out the head of the DataFrame\n","#reviews\n","apps.head(5)\n","reviews.head(5)\n","\n"]},{"cell_type":"code","execution_count":6,"id":"f020c0af","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type',\n","       'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver',\n","       'Android Ver'],\n","      dtype='object')\n","(10841, 13)\n","App                object\n","Category           object\n","Rating            float64\n","Reviews            object\n","Size               object\n","Installs           object\n","Type               object\n","Price              object\n","Content Rating     object\n","Genres             object\n","Last Updated       object\n","Current Ver        object\n","Android Ver        object\n","dtype: object\n"]}],"source":["# Perform some basic checks (column names, number of records, types, etc)\n","print(apps.columns)\n","print(apps.shape)\n","print(apps.dtypes)"]},{"cell_type":"markdown","id":"1b2a0bea-dff9-498e-9c2b-c41938786591","metadata":{},"source":["The code above works perfectly well, but this time let's try using DRY-principles to build a function to extract data.\n","\n","1. Create a function called `extract`, with a single parameter of name `file_path`.\n","2. Sprint the number of rows and columns in the DataFrame, as well as the data type of each column. Provide instructions about how to use the value that will eventually be returned by this function.\n","3. Return the variable `data`.\n","4. Call the `extract` function twice, once passing in the `apps_data.csv` file path, and another time with the `review_data.csv` file path. Output the first few rows of the `apps_data` DataFrame."]},{"cell_type":"code","execution_count":7,"id":"48c8eb8a-8e54-4296-a68d-6f3eea8189c3","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":119,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1707238826314,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# We can do this a little better. Let's try writing a function to extract the data, and print some important information\ndef extract(file_path):\n    # Read the file into memory\n    data = pd.read_csv(file_path)\n\n    # Now, print the details about the file\n    print(f\"Here is a little bit of information about the data stored in {file_path}:\")\n    print(f\"\\nThere are {data.shape[0]} rows and {data.shape[1]} columns in this DataFrame.\")\n    print(\"\\nThe columns in this DataFrame take the following types: \")\n    \n    # Print the type of each column\n    print(data.dtypes)\n    \n    # Finally, print a message before returning the DataFrame\n    print(f\"\\nTo view the DataFrame extracted from {file_path}, display the value returned by this function!\\n\\n\")\n    \n# Call the function (create apps_data and reviews_data)\napps_data = extract(file_path='apps_data.csv')\nreviews_data = extract(file_path='review_data.csv')\n# Take a peek at one of the DataFrames\nreviews_data","outputsMetadata":{"0":{"height":583,"type":"stream"},"1":{"height":320,"type":"dataFrame"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Here is a little bit of information about the data stored in apps_data.csv:\n","\n","There are 10841 rows and 13 columns in this DataFrame.\n","\n","The columns in this DataFrame take the following types: \n","App                object\n","Category           object\n","Rating            float64\n","Reviews            object\n","Size               object\n","Installs           object\n","Type               object\n","Price              object\n","Content Rating     object\n","Genres             object\n","Last Updated       object\n","Current Ver        object\n","Android Ver        object\n","dtype: object\n","\n","To view the DataFrame extracted from apps_data.csv, display the value returned by this function!\n","\n","\n","Here is a little bit of information about the data stored in review_data.csv:\n","\n","There are 64295 rows and 5 columns in this DataFrame.\n","\n","The columns in this DataFrame take the following types: \n","App                        object\n","Translated_Review          object\n","Sentiment                  object\n","Sentiment_Polarity        float64\n","Sentiment_Subjectivity    float64\n","dtype: object\n","\n","To view the DataFrame extracted from review_data.csv, display the value returned by this function!\n","\n","\n"]}],"source":["# We can do this a little better. Let's try writing a function to extract the data, and print some important information\n","def extract(file_path):\n","    # Read the file into memory\n","    data = pd.read_csv(file_path)\n","\n","    # Now, print the details about the file\n","    print(f\"Here is a little bit of information about the data stored in {file_path}:\")\n","    print(f\"\\nThere are {data.shape[0]} rows and {data.shape[1]} columns in this DataFrame.\")\n","    print(\"\\nThe columns in this DataFrame take the following types: \")\n","    \n","    # Print the type of each column\n","    print(data.dtypes)\n","    \n","    # Finally, print a message before returning the DataFrame\n","    print(f\"\\nTo view the DataFrame extracted from {file_path}, display the value returned by this function!\\n\\n\")\n","    \n","# Call the function (create apps_data and reviews_data)\n","apps_data = extract(file_path='apps_data.csv')\n","reviews_data = extract(file_path='review_data.csv')\n","# Take a peek at one of the DataFrames\n","reviews_data"]},{"cell_type":"markdown","id":"8440fbda-af1a-4244-9fbe-e156128725fb","metadata":{},"source":["# Transforming Data\n","\n","We're interested in working with the apps and their corresponding reviews in the`\"FOOD_AND_DRINK\"` category. We'd like to do the following:\n","\n","1. Define a function with name `transform`. This function will have five parameters; `apps`, `review`, `category`, `min_rating`, and `max_rating`.\n","2. Drop duplicates from both DataFrames.\n","3. For each of the apps in the desired category, find the number of positive reviews, and filter the columns.\n","4. Join this back to the `apps` dataset, only keeping the following columns:\n","    - `App`\n","    - `Rating`\n","    - `Reviews`\n","    - `Installs`\n","    - `Sentiment_Polarity`\n","5. Filter out all records that don't have at least the `min_rating`, and more than the `min_reviews`.\n","6. Order by the rating and number of installs, both in descending order.\n","7. Call the function for the `\"FOOD_AND_DRINK\"` category, with a minimum average rating of 4 stars, and at least 1000 reviews.\n","\n","Alright, let's give it a shot!\n"]},{"cell_type":"code","execution_count":8,"id":"7bb6d1b4-cce3-4502-8672-fdc424f3fc42","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":60,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1707238826374,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define a function to transform data\ndef transform(apps, reviews, category, min_rating, min_reviews):\n    # Print statement for observability\n    print(f\"Transforming data to curate a dataset with all {category} apps and their \"\n          f\"corresponding reviews with a rating of at least {min_rating} and \"\n          f\"{min_reviews} reviews\\n\")\n    \n    # Drop any duplicates from both DataFrames (also have the option to do this in-place)\n    reviews = reviews.drop_duplicates()\n    apps = apps.drop_duplicates([\"App\"])  \n    \n    # Find all of the apps and reviews in the food and drink category\n    subset_apps = apps.loc[apps[\"Category\"] == category, :]\n    subset_reviews = reviews.loc[reviews[\"App\"].isin(subset_apps[\"App\"]), [\"App\", \"Sentiment_Polarity\"]]\n    \n    # Aggregate the subset_reviews DataFrame\n    aggregated_reviews = subset_reviews.groupby(by=\"App\").mean()\n    \n    # Join it back to the subset_apps table\n    joined_apps_reviews = subset_apps.join(aggregated_reviews, on = \"App\", how=\"left\")\n    \n    # Keep only the needed columns\n    filtered_apps_reviews = joined_apps_reviews.loc[:, [\"App\", \"Rating\", \"Reviews\", \"Installs\", \"Sentiment_Polarity\"]]  \n    \n    # Convert reviews, keep only values with an average rating of at least 4 stars, and at least 1000 reviews\n    filtered_apps_reviews = filtered_apps_reviews.astype({\"Reviews\": \"int32\"})\n    top_apps = filtered_apps_reviews.loc[(filtered_apps_reviews[\"Rating\"] > min_rating) & (filtered_apps_reviews[\"Reviews\"] > min_reviews), :]\n    \n    # Sort the top apps, replace NaN with 0, reset the index (drop, inplace)\n    top_apps.sort_values(by=[\"Rating\", \"Reviews\"], ascending=False, inplace=True)\n    top_apps.reset_index(drop=True, inplace=True)\n    \n    # Persist this DataFrame as top_apps.csv file\n    top_apps.to_csv('top_apps.csv')\n    \n    print(f\"The transformed DataFrame, which includes {top_apps.shape[0]} rows \"\n          f\"and {top_apps.shape[1]} columns has been persisted, and will now be \"\n          f\"returned\")\n    \n    # Return the transformed DataFrame\n    return top_apps\n\n\n# Call the function\ntop_apps_data = transform(apps = apps_data, \n          reviews = reviews_data, \n          category = \"FOOD_AND_DRINK\", \n          min_rating = 4.0, \n          min_reviews = 1000)\n\n# Show\ntop_apps_data","outputsMetadata":{"0":{"height":77,"type":"stream"},"1":{"height":320,"type":"dataFrame"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming data to curate a dataset with all FOOD_AND_DRINK apps and their corresponding reviews with a rating of at least 4.0 and 1000 reviews\n","\n"]},{"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'drop_duplicates'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32md:\\Projects\\Portfolio\\Data Pipelines for ETL\\workspace\\workspace\\notebook.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m top_apps\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# Call the function\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m top_apps_data \u001b[39m=\u001b[39m transform(apps \u001b[39m=\u001b[39;49m apps_data, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m           reviews \u001b[39m=\u001b[39;49m reviews_data, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m           category \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mFOOD_AND_DRINK\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m           min_rating \u001b[39m=\u001b[39;49m \u001b[39m4.0\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m           min_reviews \u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Show\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m top_apps_data\n","\u001b[1;32md:\\Projects\\Portfolio\\Data Pipelines for ETL\\workspace\\workspace\\notebook.ipynb Cell 9\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTransforming data to curate a dataset with all \u001b[39m\u001b[39m{\u001b[39;00mcategory\u001b[39m}\u001b[39;00m\u001b[39m apps and their \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcorresponding reviews with a rating of at least \u001b[39m\u001b[39m{\u001b[39;00mmin_rating\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmin_reviews\u001b[39m}\u001b[39;00m\u001b[39m reviews\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Drop any duplicates from both DataFrames (also have the option to do this in-place)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m reviews \u001b[39m=\u001b[39m reviews\u001b[39m.\u001b[39;49mdrop_duplicates()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m apps \u001b[39m=\u001b[39m apps\u001b[39m.\u001b[39mdrop_duplicates([\u001b[39m\"\u001b[39m\u001b[39mApp\u001b[39m\u001b[39m\"\u001b[39m])  \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Portfolio/Data%20Pipelines%20for%20ETL/workspace/workspace/notebook.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Find all of the apps and reviews in the food and drink category\u001b[39;00m\n","\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'drop_duplicates'"]}],"source":["# Define a function to transform data\n","def transform(apps, reviews, category, min_rating, min_reviews):\n","    # Print statement for observability\n","    print(f\"Transforming data to curate a dataset with all {category} apps and their \"\n","          f\"corresponding reviews with a rating of at least {min_rating} and \"\n","          f\" {min_reviews} reviews\\n\")\n","    \n","    # Drop any duplicates from both DataFrames (also have the option to do this in-place)\n","    apps = apps.drop_duplicates([\"App\"])  \n","    reviews = reviews.drop_duplicates()\n","    \n","    # Find all of the apps and reviews in the food and drink category\n","    subset_apps = apps.loc[apps[\"Category\"] == category, :]\n","    subset_reviews = reviews.loc[reviews[\"App\"].isin(subset_apps[\"App\"]), [\"App\", \"Sentiment_Polarity\"]]\n","    \n","    # Aggregate the subset_reviews DataFrame\n","    aggregated_reviews = subset_reviews.groupby(by=\"App\").mean()\n","    \n","    # Join it back to the subset_apps table\n","    joined_apps_reviews = subset_apps.join(aggregated_reviews, on=\"App\", how=\"left\")\n","    \n","    # Keep only the needed columns\n","    filtered_apps_reviews = joined_apps_reviews.loc[:, [\"App\", \"Rating\", \"Reviews\", \"Installs\", \"Sentiment_Polarity\"]]  \n","    \n","    # Convert reviews, keep only values with an average rating of at least 4 stars, and at least 1000 reviews\n","    filtered_apps_reviews = filtered_apps_reviews.astype({\"Reviews\": \"int32\"})\n","    top_apps = filtered_apps_reviews.loc[(filtered_apps_reviews[\"Rating\"] > min_rating) & (filtered_apps_reviews[\"Reviews\"] > min_reviews), :]\n","    \n","    # Sort the top apps, replace NaN with 0, reset the index (drop, inplace)\n","    top_apps.sort_values(by=[\"Rating\", \"Reviews\"], ascending=False, inplace=True)\n","    top_apps.reset_index(drop=True, inplace=True)\n","    \n","    # Persist this DataFrame as top_apps.csv file\n","    top_apps.to_csv('top_apps.csv')\n","    \n","    print(f\"The transformed DataFrame, which includes {top_apps.shape[0]} rows \"\n","          f\"and {top_apps.shape[1]} columns has been persisted, and will now be \"\n","          f\"returned\")\n","    \n","    # Return the transformed DataFrame\n","    return top_apps\n","\n","\n","# Call the function\n","top_apps_data = transform(apps = apps_data, \n","          reviews = reviews_data, \n","          category = \"FOOD_AND_DRINK\", \n","          min_rating = 4.0, \n","          min_reviews = 1000)\n","\n","# Show\n","top_apps_data"]},{"cell_type":"markdown","id":"df9936a7-4cb6-4c95-94cc-4f5fa60351f3","metadata":{},"source":["# Loading Data\n","\n","Next, we'd like to load the transformed dataset into a SQL database. We'll be using `pandas` along with `sqlite` to do just that!\n","\n","1. After importing `sqlite3`, create a function with name `load`. The function will have four parameters; `dataframe`, `database_name`, `table_name`.\n","2. Connect to the database using the `connect()` function.\n","3. Write the DataFrame to the provided table name. Replace the table if it exists, and do not include the index.\n","4. Now, we'll validate that the data was loaded correctly. Use the `read_sql()` function to return the DataFrame that was just loaded.\n","5. Assert that the number of rows and columns match in the original and loaded DataFrame.\n","6. Return the DataFrame read from the `sqlite` database.\n","7. Call the function for the `top_apps_data` DataFrame, for the `\"market_research\"` database and the `top_apps` table."]},{"cell_type":"code","execution_count":81,"id":"20c8eb6c-f29d-4285-b416-95effb495233","metadata":{"chartConfig":{"bar":{"hasRoundedCorners":true,"stacked":false},"type":"bar","version":"v1"},"collapsed":false,"executionCancelledAt":1707238826370,"executionTime":33,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1707238512490,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import sqlite3\n\n# Now, create a function to do this\ndef load(dataframe, database_name, table_name):\n    # Create a connection object\n    con = sqlite3.connect(database_name)\n    \n    # Write the data to the specified table (table_name)\n    dataframe.to_sql(name=table_name, con=con, if_exists=\"replace\", index=False)\n    print(\"Original DataFrame has been loaded to sqlite\\n\")\n    \n    # Read the data, and return the result (it is to be used)\n    loaded_dataframe = pd.read_sql(sql = f\"SELECT * FROM {table_name}\", con=con)\n    print(\"The loaded DataFrame has been read from sqlite for validation\\n\")\n    \n    try:\n        assert dataframe.shape == loaded_dataframe.shape\n        print(f\"Success! The data in the {table_name} table have successfully been \"\n              f\"loaded and validated\")\n\n    except AssertionError:\n        print(\"DataFrame shape is not consistent before and after loading. Take a closer look!\")\n\n# Call the function\nload(\n    dataframe=top_apps_data,\n    database_name= \"market_research\",\n    table_name=\"top_apps\"\n)    ","outputsMetadata":{"0":{"height":117,"type":"stream"},"1":{"height":320,"type":"dataFrame"}},"visualizeDataframe":false},"outputs":[{"ename":"NameError","evalue":"name 'top_apps_data' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame shape is not consistent before and after loading. Take a closer look!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Call the function\u001b[39;00m\n\u001b[1;32m     25\u001b[0m load(\n\u001b[0;32m---> 26\u001b[0m     dataframe\u001b[38;5;241m=\u001b[39m\u001b[43mtop_apps_data\u001b[49m,\n\u001b[1;32m     27\u001b[0m     database_name\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarket_research\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     table_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_apps\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m )\n","\u001b[0;31mNameError\u001b[0m: name 'top_apps_data' is not defined"]}],"source":["import sqlite3\n","\n","# Now, create a function to do this\n","def load(dataframe, database_name, table_name):\n","    # Create a connection object\n","    con = sqlite3.connect(database_name)\n","    \n","    # Write the data to the specified table (table_name)\n","    dataframe.to_sql(name=table_name, con=con, if_exists=\"replace\", index=False)\n","    print(\"Original DataFrame has been loaded to sqlite\\n\")\n","    \n","    # Read the data, and return the result (it is to be used)\n","    loaded_dataframe = pd.read_sql(sql = f\"SELECT * FROM {table_name}\", con=con)\n","    print(\"The loaded DataFrame has been read from sqlite for validation\\n\")\n","    \n","    try:\n","        assert dataframe.shape == loaded_dataframe.shape\n","        print(f\"Success! The data in the {table_name} table have successfully been \"\n","              f\"loaded and validated\")\n","\n","    except AssertionError:\n","        print(\"DataFrame shape is not consistent before and after loading. Take a closer look!\")\n","\n","# Call the function\n","load(\n","    dataframe=top_apps_data,\n","    database_name= \"market_research\",\n","    table_name=\"top_apps\"\n",")    "]},{"cell_type":"markdown","id":"04ad98ed-d466-464f-a8ed-232347637108","metadata":{},"source":["# Running the Pipeline\n","\n","Now that our functions have been defined and tested, we'll run this pipeline end-to-end!\n","\n","1. For verbosity, import `pandas` and `sqlite3`.\n","2. Extract data from the `apps_data.csv` and `review_data.csv` functions.\n","3. Transform the data by passing in the following:\n","    - `category=\"FOOD_AND_DRINK\"`\n","    - `min_rating=4.0`\n","    - `min_reviews=1000`\n","4. Load the transformed DataFrame to the `top_apps` table in the `market_research` database.\n","5. Check out the output!\n","\n"]},{"cell_type":"code","execution_count":15,"id":"f4956986-a2be-44ff-9f70-41eaa39040ef","metadata":{"collapsed":false,"executionCancelledAt":1707238826372,"executionTime":116,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1707238593742,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import modules\nimport pandas as pd\nimport sqlite3\n\n# Extract the data\napps_data = extract(\"apps_data.csv\")\nreviews_data = extract(\"review_data.csv\")","outputsMetadata":{"0":{"height":583,"type":"stream"},"1":{"height":323,"type":"dataFrame"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Here is a little bit of information about the data stored in apps_data.csv:\n","\n","There are 10841 rows and 13 columns in this DataFrame.\n","\n","The columns in this DataFrame take the following types: \n","App                object\n","Category           object\n","Rating            float64\n","Reviews            object\n","Size               object\n","Installs           object\n","Type               object\n","Price              object\n","Content Rating     object\n","Genres             object\n","Last Updated       object\n","Current Ver        object\n","Android Ver        object\n","dtype: object\n","\n","To view the DataFrame extracted from apps_data.csv, display the value returned by this function!\n","\n","\n","Here is a little bit of information about the data stored in review_data.csv:\n","\n","There are 64295 rows and 5 columns in this DataFrame.\n","\n","The columns in this DataFrame take the following types: \n","App                        object\n","Translated_Review          object\n","Sentiment                  object\n","Sentiment_Polarity        float64\n","Sentiment_Subjectivity    float64\n","dtype: object\n","\n","To view the DataFrame extracted from review_data.csv, display the value returned by this function!\n","\n","\n"]}],"source":["# Import modules\n","import pandas as pd\n","import sqlite3\n","\n","# Extract the data\n","apps_data = extract(\"apps_data.csv\")\n","reviews_data = extract(\"review_data.csv\")"]},{"cell_type":"code","execution_count":83,"id":"4dd60d62-e78c-4398-a112-d63d45a53505","metadata":{"collapsed":false,"executionCancelledAt":1707238826373,"executionTime":null,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":97,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming data to curate a dataset with all FOOD_AND_DRINK apps and their corresponding reviews with a rating of at least 4.0 and  1000 reviews\n","\n","The transformed DataFrame, which includes 54 rows and 5 columns has been persisted, and will now be returned\n"]}],"source":["# Transform the data\n","top_apps_data = transform(apps = apps_data, \n","          reviews = reviews_data, \n","          category = \"FOOD_AND_DRINK\", \n","          min_rating = 4.0, \n","          min_reviews = 1000)\n"]},{"cell_type":"code","execution_count":84,"id":"9514ee86-413b-418d-b1ca-c6927d09d0fc","metadata":{"collapsed":false,"executionCancelledAt":1707238826373,"executionTime":284,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1706998579752,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load the data\nload(\n    dataframe=top_apps_data,\n    database_name=\"market_research\",\n    table_name=\"top_apps\"\n)\n","outputsMetadata":{"0":{"height":117,"type":"stream"},"1":{"height":320,"type":"dataFrame"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Original DataFrame has been loaded to sqlite\n","\n","The loaded DataFrame has been read from sqlite for validation\n","\n","Success! The data in the top_apps table have successfully been loaded and validated\n"]},{"data":{"application/com.datacamp.data-table.v2+json":{"table":{"data":{"App":["SarashpazPapion (Cooking with Chef Bowls)","Domino's Pizza USA","Tastely","Delicious Recipes","BeyondMenu Food Delivery","Recipes Pastries and homemade pies More than 500 recipes for pastries","Pastry & Cooking (Without Net)","Simple Recipes","Easy Recipes","OpenTable: Restaurants Near Me","DELISH KITCHEN - FREE recipe movies make food fun and easy!","Kitchen Stories - Recipes & Cooking","My Recipes Cookbook : RecetteTek","EatStreet Food Delivery App","Eat Fast Prepare \"Without Internet\"","My CookBook Pro (Ad Free)","Easy and quick desserts","Starbucks","Grubhub: Food Delivery","Cookpad","Talabat: Food Delivery","DoorDash - Food Delivery","Yummly Recipes & Shopping List","Allrecipes Dinner Spinner","Seamless Food Delivery/Takeout","My CookBook (Recipe Manager)","ChefTap Recipes & Grocery List","Whataburger","BURGER KING® Puerto Rico","Pizza Hut","Delivery yogi.","Instacart: Grocery Delivery","Recipe Keeper","Zomato - Restaurant Finder and Food Delivery App","Delivery Club-food delivery: pizza, sushi, burger, salad","Delivery trough - delivery trough delivery trough","Eat24 Food Delivery & Takeout","TheFork - Restaurants booking and special offers","BigOven Recipes, Meal Planner, Grocery List & More","GialloZafferano: Recipes","Chick-fil-A","SONIC Drive-In","Uber Eats: Local Food Delivery","Dunkin' Donuts","Panera Bread","Dr. Oetker recipe ideas","Caviar - Food Delivery","Foursquare City Guide","Cookpad - FREE recipe search makes fun cooking · musical making!","Cookbook Recipes","Chef - Recipes & Cooking","Frigo Magic: Easy recipe idea and anti-waste","delivery.com: Order Food, Alcohol & Laundry","Paprika Recipe Manager"],"Installs":["50,000+","10,000,000+","10,000,000+","1,000,000+","1,000,000+","500,000+","1,000,000+","500,000+","100,000+","5,000,000+","1,000,000+","1,000,000+","100,000+","100,000+","1,000,000+","10,000+","100,000+","10,000,000+","5,000,000+","10,000,000+","5,000,000+","1,000,000+","1,000,000+","5,000,000+","1,000,000+","1,000,000+","500,000+","500,000+","100,000+","10,000,000+","10,000,000+","1,000,000+","100,000+","10,000,000+","5,000,000+","5,000,000+","1,000,000+","5,000,000+","1,000,000+","1,000,000+","5,000,000+","1,000,000+","10,000,000+","1,000,000+","1,000,000+","1,000,000+","100,000+","10,000,000+","10,000,000+","5,000,000+","5,000,000+","500,000+","100,000+","50,000+"],"Rating":[4.8,4.7,4.7,4.7,4.7,4.7,4.7,4.7,4.7,4.6,4.6,4.6,4.6,4.6,4.6,4.6,4.6,4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.4,4.4,4.4,4.4,4.3,4.3,4.3,4.3,4.3,4.3,4.3,4.3,4.3,4.2,4.2,4.2,4.2,4.2,4.1,4.1,4.1,4.1,4.1,4.1,4.1],"Reviews":[1250,1032935,611136,129737,51517,14065,6118,3803,2707,90242,32997,22015,11707,7690,4925,2129,1398,455377,155944,131569,116403,104504,91359,61881,35218,22071,9066,5093,2448,321134,90042,17071,1962,511228,151080,58316,40116,37517,31986,30224,28008,19314,333208,68103,10159,8509,3755,483960,64784,46539,32405,2473,1920,1268],"Sentiment_Polarity":[null,0.2269709094,null,null,0.4087426901,null,null,null,0.2847770468,null,null,null,null,0.3832653026,null,null,null,null,0.1227393294,0.2574367685,null,0.072407103,null,0.2729995443,null,null,null,null,null,null,null,null,null,null,null,null,0.1716105214,null,0.3282224026,null,null,null,null,0.1965599298,null,null,0.2173747809,0.2002786797,null,0.5654370381,null,null,null,null],"index":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53]},"schema":{"fields":[{"name":"index","type":"integer"},{"name":"App","type":"string"},{"name":"Rating","type":"number"},{"name":"Reviews","type":"integer"},{"name":"Installs","type":"string"},{"name":"Sentiment_Polarity","type":"number"}],"pandas_version":"1.4.0","primaryKey":["index"]}},"total_rows":54,"truncation_type":null},"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>App</th>\n","      <th>Rating</th>\n","      <th>Reviews</th>\n","      <th>Installs</th>\n","      <th>Sentiment_Polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>SarashpazPapion (Cooking with Chef Bowls)</td>\n","      <td>4.8</td>\n","      <td>1250</td>\n","      <td>50,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Domino's Pizza USA</td>\n","      <td>4.7</td>\n","      <td>1032935</td>\n","      <td>10,000,000+</td>\n","      <td>0.226971</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Tastely</td>\n","      <td>4.7</td>\n","      <td>611136</td>\n","      <td>10,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Delicious Recipes</td>\n","      <td>4.7</td>\n","      <td>129737</td>\n","      <td>1,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>BeyondMenu Food Delivery</td>\n","      <td>4.7</td>\n","      <td>51517</td>\n","      <td>1,000,000+</td>\n","      <td>0.408743</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Recipes Pastries and homemade pies More than 5...</td>\n","      <td>4.7</td>\n","      <td>14065</td>\n","      <td>500,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Pastry &amp; Cooking (Without Net)</td>\n","      <td>4.7</td>\n","      <td>6118</td>\n","      <td>1,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Simple Recipes</td>\n","      <td>4.7</td>\n","      <td>3803</td>\n","      <td>500,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Easy Recipes</td>\n","      <td>4.7</td>\n","      <td>2707</td>\n","      <td>100,000+</td>\n","      <td>0.284777</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>OpenTable: Restaurants Near Me</td>\n","      <td>4.6</td>\n","      <td>90242</td>\n","      <td>5,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>DELISH KITCHEN - FREE recipe movies make food ...</td>\n","      <td>4.6</td>\n","      <td>32997</td>\n","      <td>1,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Kitchen Stories - Recipes &amp; Cooking</td>\n","      <td>4.6</td>\n","      <td>22015</td>\n","      <td>1,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>My Recipes Cookbook : RecetteTek</td>\n","      <td>4.6</td>\n","      <td>11707</td>\n","      <td>100,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>EatStreet Food Delivery App</td>\n","      <td>4.6</td>\n","      <td>7690</td>\n","      <td>100,000+</td>\n","      <td>0.383265</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Eat Fast Prepare \"Without Internet\"</td>\n","      <td>4.6</td>\n","      <td>4925</td>\n","      <td>1,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>My CookBook Pro (Ad Free)</td>\n","      <td>4.6</td>\n","      <td>2129</td>\n","      <td>10,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Easy and quick desserts</td>\n","      <td>4.6</td>\n","      <td>1398</td>\n","      <td>100,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Starbucks</td>\n","      <td>4.5</td>\n","      <td>455377</td>\n","      <td>10,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Grubhub: Food Delivery</td>\n","      <td>4.5</td>\n","      <td>155944</td>\n","      <td>5,000,000+</td>\n","      <td>0.122739</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Cookpad</td>\n","      <td>4.5</td>\n","      <td>131569</td>\n","      <td>10,000,000+</td>\n","      <td>0.257437</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Talabat: Food Delivery</td>\n","      <td>4.5</td>\n","      <td>116403</td>\n","      <td>5,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>DoorDash - Food Delivery</td>\n","      <td>4.5</td>\n","      <td>104504</td>\n","      <td>1,000,000+</td>\n","      <td>0.072407</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Yummly Recipes &amp; Shopping List</td>\n","      <td>4.5</td>\n","      <td>91359</td>\n","      <td>1,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Allrecipes Dinner Spinner</td>\n","      <td>4.5</td>\n","      <td>61881</td>\n","      <td>5,000,000+</td>\n","      <td>0.273000</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Seamless Food Delivery/Takeout</td>\n","      <td>4.5</td>\n","      <td>35218</td>\n","      <td>1,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>My CookBook (Recipe Manager)</td>\n","      <td>4.5</td>\n","      <td>22071</td>\n","      <td>1,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>ChefTap Recipes &amp; Grocery List</td>\n","      <td>4.5</td>\n","      <td>9066</td>\n","      <td>500,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Whataburger</td>\n","      <td>4.5</td>\n","      <td>5093</td>\n","      <td>500,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>BURGER KING® Puerto Rico</td>\n","      <td>4.5</td>\n","      <td>2448</td>\n","      <td>100,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Pizza Hut</td>\n","      <td>4.4</td>\n","      <td>321134</td>\n","      <td>10,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Delivery yogi.</td>\n","      <td>4.4</td>\n","      <td>90042</td>\n","      <td>10,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Instacart: Grocery Delivery</td>\n","      <td>4.4</td>\n","      <td>17071</td>\n","      <td>1,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>Recipe Keeper</td>\n","      <td>4.4</td>\n","      <td>1962</td>\n","      <td>100,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>Zomato - Restaurant Finder and Food Delivery App</td>\n","      <td>4.3</td>\n","      <td>511228</td>\n","      <td>10,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>Delivery Club-food delivery: pizza, sushi, bur...</td>\n","      <td>4.3</td>\n","      <td>151080</td>\n","      <td>5,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>Delivery trough - delivery trough delivery trough</td>\n","      <td>4.3</td>\n","      <td>58316</td>\n","      <td>5,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>Eat24 Food Delivery &amp; Takeout</td>\n","      <td>4.3</td>\n","      <td>40116</td>\n","      <td>1,000,000+</td>\n","      <td>0.171611</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>TheFork - Restaurants booking and special offers</td>\n","      <td>4.3</td>\n","      <td>37517</td>\n","      <td>5,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>BigOven Recipes, Meal Planner, Grocery List &amp; ...</td>\n","      <td>4.3</td>\n","      <td>31986</td>\n","      <td>1,000,000+</td>\n","      <td>0.328222</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>GialloZafferano: Recipes</td>\n","      <td>4.3</td>\n","      <td>30224</td>\n","      <td>1,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>Chick-fil-A</td>\n","      <td>4.3</td>\n","      <td>28008</td>\n","      <td>5,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>SONIC Drive-In</td>\n","      <td>4.3</td>\n","      <td>19314</td>\n","      <td>1,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>Uber Eats: Local Food Delivery</td>\n","      <td>4.2</td>\n","      <td>333208</td>\n","      <td>10,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>Dunkin' Donuts</td>\n","      <td>4.2</td>\n","      <td>68103</td>\n","      <td>1,000,000+</td>\n","      <td>0.196560</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>Panera Bread</td>\n","      <td>4.2</td>\n","      <td>10159</td>\n","      <td>1,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>Dr. Oetker recipe ideas</td>\n","      <td>4.2</td>\n","      <td>8509</td>\n","      <td>1,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>Caviar - Food Delivery</td>\n","      <td>4.2</td>\n","      <td>3755</td>\n","      <td>100,000+</td>\n","      <td>0.217375</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>Foursquare City Guide</td>\n","      <td>4.1</td>\n","      <td>483960</td>\n","      <td>10,000,000+</td>\n","      <td>0.200279</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>Cookpad - FREE recipe search makes fun cooking...</td>\n","      <td>4.1</td>\n","      <td>64784</td>\n","      <td>10,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>Cookbook Recipes</td>\n","      <td>4.1</td>\n","      <td>46539</td>\n","      <td>5,000,000+</td>\n","      <td>0.565437</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>Chef - Recipes &amp; Cooking</td>\n","      <td>4.1</td>\n","      <td>32405</td>\n","      <td>5,000,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>Frigo Magic: Easy recipe idea and anti-waste</td>\n","      <td>4.1</td>\n","      <td>2473</td>\n","      <td>500,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>delivery.com: Order Food, Alcohol &amp; Laundry</td>\n","      <td>4.1</td>\n","      <td>1920</td>\n","      <td>100,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>Paprika Recipe Manager</td>\n","      <td>4.1</td>\n","      <td>1268</td>\n","      <td>50,000+</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                  App  ...  Sentiment_Polarity\n","0           SarashpazPapion (Cooking with Chef Bowls)  ...                 NaN\n","1                                  Domino's Pizza USA  ...            0.226971\n","2                                             Tastely  ...                 NaN\n","3                                   Delicious Recipes  ...                 NaN\n","4                            BeyondMenu Food Delivery  ...            0.408743\n","5   Recipes Pastries and homemade pies More than 5...  ...                 NaN\n","6                      Pastry & Cooking (Without Net)  ...                 NaN\n","7                                      Simple Recipes  ...                 NaN\n","8                                        Easy Recipes  ...            0.284777\n","9                      OpenTable: Restaurants Near Me  ...                 NaN\n","10  DELISH KITCHEN - FREE recipe movies make food ...  ...                 NaN\n","11                Kitchen Stories - Recipes & Cooking  ...                 NaN\n","12                   My Recipes Cookbook : RecetteTek  ...                 NaN\n","13                        EatStreet Food Delivery App  ...            0.383265\n","14                Eat Fast Prepare \"Without Internet\"  ...                 NaN\n","15                          My CookBook Pro (Ad Free)  ...                 NaN\n","16                            Easy and quick desserts  ...                 NaN\n","17                                          Starbucks  ...                 NaN\n","18                             Grubhub: Food Delivery  ...            0.122739\n","19                                            Cookpad  ...            0.257437\n","20                             Talabat: Food Delivery  ...                 NaN\n","21                           DoorDash - Food Delivery  ...            0.072407\n","22                     Yummly Recipes & Shopping List  ...                 NaN\n","23                          Allrecipes Dinner Spinner  ...            0.273000\n","24                     Seamless Food Delivery/Takeout  ...                 NaN\n","25                       My CookBook (Recipe Manager)  ...                 NaN\n","26                     ChefTap Recipes & Grocery List  ...                 NaN\n","27                                        Whataburger  ...                 NaN\n","28                           BURGER KING® Puerto Rico  ...                 NaN\n","29                                          Pizza Hut  ...                 NaN\n","30                                     Delivery yogi.  ...                 NaN\n","31                        Instacart: Grocery Delivery  ...                 NaN\n","32                                      Recipe Keeper  ...                 NaN\n","33   Zomato - Restaurant Finder and Food Delivery App  ...                 NaN\n","34  Delivery Club-food delivery: pizza, sushi, bur...  ...                 NaN\n","35  Delivery trough - delivery trough delivery trough  ...                 NaN\n","36                      Eat24 Food Delivery & Takeout  ...            0.171611\n","37   TheFork - Restaurants booking and special offers  ...                 NaN\n","38  BigOven Recipes, Meal Planner, Grocery List & ...  ...            0.328222\n","39                           GialloZafferano: Recipes  ...                 NaN\n","40                                        Chick-fil-A  ...                 NaN\n","41                                     SONIC Drive-In  ...                 NaN\n","42                     Uber Eats: Local Food Delivery  ...                 NaN\n","43                                     Dunkin' Donuts  ...            0.196560\n","44                                       Panera Bread  ...                 NaN\n","45                            Dr. Oetker recipe ideas  ...                 NaN\n","46                             Caviar - Food Delivery  ...            0.217375\n","47                              Foursquare City Guide  ...            0.200279\n","48  Cookpad - FREE recipe search makes fun cooking...  ...                 NaN\n","49                                   Cookbook Recipes  ...            0.565437\n","50                           Chef - Recipes & Cooking  ...                 NaN\n","51       Frigo Magic: Easy recipe idea and anti-waste  ...                 NaN\n","52        delivery.com: Order Food, Alcohol & Laundry  ...                 NaN\n","53                             Paprika Recipe Manager  ...                 NaN\n","\n","[54 rows x 5 columns]"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["# Load the data\n","load(\n","    dataframe=top_apps_data,\n","    database_name= \"market_research\",\n","    table_name=\"top_apps\"\n",")    \n"]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}
